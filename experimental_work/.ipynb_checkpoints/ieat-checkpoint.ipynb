{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automotive-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "complicated-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implements the WEAT tests \n",
    "Adapted from https://github.com/W4ngatang/sent-bias/blob/master/sentbias/weat.py\n",
    "'''\n",
    "import logging as log\n",
    "import math\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import argparse\n",
    "\n",
    "# X and Y are two sets of target words of equal size.\n",
    "# A and B are two sets of attribute words.\n",
    "\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, X, Y, A, B, names=None):\n",
    "        \"\"\"\n",
    "        A WEAT Test.\n",
    "        :param X: A set of target embeddings\n",
    "        :param Y: A set of target embeddings\n",
    "        :param A: A set of attribute embeddings\n",
    "        :param B: A set of attribute embeddings\n",
    "        :param names: Optional set of names for X, Y, A, and B, in order\n",
    "        :return: the effect size and p-value\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.names = names if names is not None else [\"X\", \"Y\", \"A\", \"B\"]\n",
    "        self.reset_calc()\n",
    "\n",
    "    def reset_calc(self):\n",
    "        log.info(\"Computing cosine similarities...\")\n",
    "        self.similarity_matrix = self.similarities()\n",
    "        self.s_AB = None\n",
    "        self.calc_s_AB()\n",
    "\n",
    "    def run(self, randomized=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the test.\n",
    "        \"\"\"\n",
    "        if randomized:\n",
    "            X_orig = self.X\n",
    "            Y_orig = self.Y\n",
    "            A_orig = self.A\n",
    "            B_orig = self.B\n",
    "            D = np.concatenate((self.X, self.Y, self.A, self.B))\n",
    "            np.random.shuffle(D)\n",
    "            self.X = D[:X_orig.shape[0],:]\n",
    "            self.Y = D[X_orig.shape[0]:2*X_orig.shape[0],:]\n",
    "            self.A = D[2*X_orig.shape[0]:2*X_orig.shape[0]+A_orig.shape[0], :]\n",
    "            self.B = D[2*X_orig.shape[0]+A_orig.shape[0]:, :]\n",
    "            self.reset_calc()\n",
    "\n",
    "\n",
    "        p = self.p(**kwargs)\n",
    "        log.info(\"pval: %g\", p)\n",
    "\n",
    "        log.info(\"computing effect size...\")\n",
    "        e = self.effect_size()\n",
    "        log.info(\"esize: %g\", e)\n",
    "\n",
    "        if randomized:\n",
    "            self.X = X_orig\n",
    "            self.Y = Y_orig\n",
    "            self.A = A_orig\n",
    "            self.B = B_orig\n",
    "            self.reset_calc()\n",
    "        return e, p  \n",
    "\n",
    "    def similarities(self):\n",
    "        \"\"\"\n",
    "        :return: an array of size (len(XY), len(AB)) containing cosine similarities\n",
    "        between items in XY and items in AB.\n",
    "        \"\"\"\n",
    "        XY = np.concatenate((self.X, self.Y))\n",
    "        AB = np.concatenate((self.A, self.B))\n",
    "        return cosine_similarity(XY, AB)\n",
    "\n",
    "    def calc_s_AB(self):\n",
    "        self.s_AB = self.s_wAB(np.arange(self.similarity_matrix.shape[0]))\n",
    "\n",
    "    def s_wAB(self, w):\n",
    "        \"\"\"\n",
    "        Return vector of s(w, A, B) across w, where\n",
    "            s(w, A, B) = mean_{a in A} cos(w, a) - mean_{b in B} cos(w, b).\n",
    "        :param w: Mask on the XY axis of similarity matrix\n",
    "        \"\"\"\n",
    "        return self.similarity_matrix[w, :self.A.shape[0]].mean(axis=1) - self.similarity_matrix[w, self.A.shape[0]:].mean(axis=1)\n",
    "\n",
    "    def s_XAB(self, mask):\n",
    "        r\"\"\"\n",
    "        Given indices of target concept X and precomputed s_wAB values,\n",
    "        return slightly more computationally efficient version of WEAT\n",
    "        statistic for p-value computation.\n",
    "        Caliskan defines the WEAT statistic s(X, Y, A, B) as\n",
    "            sum_{x in X} s(x, A, B) - sum_{y in Y} s(y, A, B)\n",
    "        where s(w, A, B) is defined as\n",
    "            mean_{a in A} cos(w, a) - mean_{b in B} cos(w, b).\n",
    "        The p-value is computed using a permutation test on (X, Y) over all\n",
    "        partitions (X', Y') of X union Y with |X'| = |Y'|.\n",
    "        However, for all partitions (X', Y') of X union Y,\n",
    "            s(X', Y', A, B)\n",
    "          = sum_{x in X'} s(x, A, B) + sum_{y in Y'} s(y, A, B)\n",
    "          = C,\n",
    "        a constant.  Thus\n",
    "            sum_{x in X'} s(x, A, B) + sum_{y in Y'} s(y, A, B)\n",
    "          = sum_{x in X'} s(x, A, B) + (C - sum_{x in X'} s(x, A, B))\n",
    "          = C + 2 sum_{x in X'} s(x, A, B).\n",
    "        By monotonicity,\n",
    "            s(X', Y', A, B) > s(X, Y, A, B)\n",
    "        if and only if\n",
    "            [s(X', Y', A, B) - C] / 2 > [s(X, Y, A, B) - C] / 2,\n",
    "        that is,\n",
    "            sum_{x in X'} s(x, A, B) > sum_{x in X} s(x, A, B).\n",
    "        Thus we only need use the first component of s(X, Y, A, B) as our\n",
    "        test statistic.\n",
    "        :param mask: some random X partition of XY - in the form of a mask on XY\n",
    "        \"\"\"\n",
    "        return self.s_AB[mask].sum()\n",
    "\n",
    "    def s_XYAB(self, X, Y):\n",
    "        r\"\"\"\n",
    "        Given indices of target concept X and precomputed s_wAB values,\n",
    "        the WEAT test statistic for p-value computation.\n",
    "        :param X: Mask for XY indicating the values in partition X\n",
    "        :param Y: Mask for XY indicating the values in partition Y\n",
    "        \"\"\"\n",
    "        return self.s_XAB(X) - self.s_XAB(Y)\n",
    "\n",
    "    def p(self, n_samples=10000, parametric=False):\n",
    "        \"\"\" \n",
    "        Compute the p-val for the permutation test, which is defined as\n",
    "        the probability that a random even partition X_i, Y_i of X u Y\n",
    "        satisfies P[s(X_i, Y_i, A, B) > s(X, Y, A, B)]\n",
    "        \"\"\"\n",
    "        assert self.X.shape[0] == self.Y.shape[0]\n",
    "        size = self.X.shape[0]\n",
    "\n",
    "        XY = np.concatenate((self.X, self.Y))\n",
    "\n",
    "        if parametric:\n",
    "            log.info('Using parametric test')\n",
    "            s = self.s_XYAB(np.arange(self.X.shape[0]), np.arange(self.X.shape[0], self.X.shape[0]+self.Y.shape[0]))\n",
    "\n",
    "            log.info('Drawing {} samples'.format(n_samples))\n",
    "            samples = []\n",
    "            for _ in range(n_samples):\n",
    "                a = np.arange(XY.shape[0])\n",
    "                np.random.shuffle(a)\n",
    "                Xi = a[:size]\n",
    "                Yi = a[size:]\n",
    "                assert len(Xi) == len(Yi)\n",
    "                si = self.s_XYAB(Xi, Yi)\n",
    "                samples.append(si)\n",
    "\n",
    "            # Compute sample standard deviation and compute p-value by\n",
    "            # assuming normality of null distribution\n",
    "            log.info('Inferring p-value based on normal distribution')\n",
    "            (shapiro_test_stat, shapiro_p_val) = scipy.stats.shapiro(samples)\n",
    "            log.info('Shapiro-Wilk normality test statistic: {:.2g}, p-value: {:.2g}'.format(\n",
    "                shapiro_test_stat, shapiro_p_val))\n",
    "            sample_mean = np.mean(samples)\n",
    "            sample_std = np.std(samples, ddof=1)\n",
    "            log.info('Sample mean: {:.2g}, sample standard deviation: {:.2g}'.format(\n",
    "                sample_mean, sample_std))\n",
    "            p_val = scipy.stats.norm.sf(s, loc=sample_mean, scale=sample_std)\n",
    "            return p_val\n",
    "\n",
    "        else:\n",
    "            log.info('Using non-parametric test')\n",
    "            s = self.s_XAB(np.arange(self.X.shape[0]))\n",
    "            total_true = 0\n",
    "            total_equal = 0\n",
    "            total = 0\n",
    "\n",
    "            num_partitions = int(scipy.special.binom(2 * self.X.shape[0], self.X.shape[0]))\n",
    "            if num_partitions > n_samples:\n",
    "                # We only have as much precision as the number of samples drawn;\n",
    "                # bias the p-value (hallucinate a positive observation) to\n",
    "                # reflect that.\n",
    "                total_true += 1\n",
    "                total += 1\n",
    "                log.info('Drawing {} samples (and biasing by 1)'.format(n_samples - total))\n",
    "                for i in range(n_samples - 1):\n",
    "                    a = np.arange(XY.shape[0])\n",
    "                    np.random.shuffle(a)\n",
    "                    Xi = a[:size]\n",
    "                    assert 2 * len(Xi) == len(XY)\n",
    "                    si = self.s_XAB(Xi)\n",
    "                    if si > s:\n",
    "                        total_true += 1\n",
    "                    elif si == s:  # use conservative test\n",
    "                        total_true += 1\n",
    "                        total_equal += 1\n",
    "                    total += 1\n",
    "            else:\n",
    "                log.info('Using exact test ({} partitions)'.format(num_partitions))\n",
    "                # iterate through all possible X-length combinations of the indices of XY\n",
    "                for Xi in it.combinations(np.arange(XY.shape[0]), self.X.shape[0]):\n",
    "                    assert 2 * len(Xi) == len(XY)\n",
    "                    si = self.s_XAB(np.array(Xi))\n",
    "                    if si > s:\n",
    "                        total_true += 1\n",
    "                    elif si == s:  # use conservative test\n",
    "                        total_true += 1\n",
    "                        total_equal += 1\n",
    "                    total += 1\n",
    "\n",
    "            if total_equal:\n",
    "                log.warning('Equalities contributed {}/{} to p-value'.format(total_equal, total))\n",
    "\n",
    "            return total_true / total\n",
    "\n",
    "    def effect_size(self):\n",
    "        \"\"\"\n",
    "        Compute the effect size, which is defined as\n",
    "            [mean_{x in X} s(x, A, B) - mean_{y in Y} s(y, A, B)] /\n",
    "                [ stddev_{w in X u Y} s(w, A, B) ]\n",
    "        args:\n",
    "            - X, Y, A, B : sets of target (X, Y) and attribute (A, B) indices\n",
    "        \"\"\"\n",
    "        numerator = np.mean(self.s_wAB(np.arange(self.X.shape[0]))) - np.mean(self.s_wAB(np.arange(self.X.shape[0], self.similarity_matrix.shape[0])))\n",
    "        denominator = np.std(self.s_AB, ddof=1)\n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "guided-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(folder, pca):\n",
    "    #features_pt = os.listdir(folder+'/pretrained_features/')\n",
    "    if pca==0.0:\n",
    "        pca_path = 'no_pca/'\n",
    "    else:\n",
    "        pca_path = 'pca/'\n",
    "\n",
    "    features = dict()\n",
    "    features_pt = os.listdir(folder+'/pretrained_features/'+pca_path)\n",
    "    features_ft = os.listdir(folder+'/finetuned_features/'+pca_path)\n",
    "    for file_name in features_pt:\n",
    "        features[os.path.splitext(file_name)[0]] = np.load(folder + '/pretrained_features/' + pca_path + file_name, allow_pickle=True)\n",
    "    for file_name in features_ft:\n",
    "        features[os.path.splitext(file_name)[0]] = np.load(folder + '/finetuned_features/' + pca_path + file_name, allow_pickle=True)\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_ieat_features(model_name, dataset):\n",
    "    trials = os.listdir('../experiments/'+dataset+'/'+model_name) \n",
    "    trials.remove('orig')\n",
    "    all_features = []\n",
    "    for trial in trials:\n",
    "        features = load_features('../experiments/'+dataset+'/'+model_name+'/'+trial, pca=0.0)\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def run_test(X, Y, A, B, features, n_samples=10000):\n",
    "    np.random.seed(38)\n",
    "    pvals = []\n",
    "    effect_sizes = []\n",
    "    for feature_trial in features:\n",
    "        cap = min(feature_trial[X].shape[0], feature_trial[Y].shape[0])\n",
    "        test = Test(feature_trial[X][:cap], feature_trial[Y][:cap], feature_trial[A], feature_trial[B])\n",
    "        pval = test.run(n_samples=n_samples)\n",
    "        print(\"Effect Size: \", pval[0])\n",
    "        print(\"Pval: \", pval[1])\n",
    "        effect_sizes.append(pval[0])\n",
    "        pavls.append(pval[1])\n",
    "    return np.mean(effect_sizes), np.mean(pvals) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-passport",
   "metadata": {},
   "source": [
    "# COCO Analysis Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eastern-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cm_pt', 'random_pt', 'sm_pt', 'cw_pt', 'man_pt', 'sw_pt', 'stop_pt', 'ma_pt', 'fm_pt', 'woman_pt', 'fw_pt', 'fa_pt', 'mm_pt', 'ca_pt', 'mw_pt', 'sa_pt', 'sm_ft', 'cm_ft', 'ma_ft', 'sw_ft', 'cw_ft', 'man_ft', 'random_ft', 'fm_ft', 'fw_ft', 'woman_ft', 'fa_ft', 'mm_ft', 'sa_ft', 'mw_ft', 'ca_ft', 'stop_ft'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit_features = load_ieat_features('bit_resnet50', 'coco')\n",
    "run_test('man_pt', 'woman_pt', 'sa_pt', 'ra_pt', bit_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
